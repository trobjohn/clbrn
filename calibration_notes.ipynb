{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Calibration plot: $\\hat{p}$ on horizontal, $p$ on vertical. Kernal regression or bins.\n",
    "\n",
    "$$\n",
    "\\widehat{\\mathbb{E}}[p] = \\dfrac{1}{N} \\sum_{i=1}^N d_i\n",
    "$$\n",
    "\n",
    "\n",
    "Hosmer–Lemeshow goodness-of-fit test\n",
    "\n",
    "\n",
    "\n",
    "Lorenz curve/Gini coefficient: For a level $\\hat{p}$ of predicted risk, there should be $p$ proportion of realized risk in the population\n",
    "\n",
    "\n",
    "To condition on $\\hat{p}$, we can use a kernel estimator,\n",
    "$$\n",
    "\\widehat{\\mathbb{E}}[p|\\hat{p}] =  \\dfrac{\\dfrac{1}{N} \\sum_{i=1}^N d_i \\times k_h(p-\\hat{p}_i)}{\\dfrac{1}{N} \\sum_{i=1}^N k_h(p-\\hat{p}_i)} = \\gamma(\\hat{p})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For linear regression:\n",
    "$$\n",
    "y' = a + b \\times \\hat{y}\n",
    "$$\n",
    "\n",
    "\n",
    "For logistic regression:\n",
    "$$\n",
    "\\text{logit}( \\hat{p}' ) = a + b \\times x_i \\hat{\\beta}\n",
    "$$\n",
    "\n",
    "\n",
    "The coefficient $b$ is the **calibration slope**. If $\\hat{b}<1$, then shrinkage of regression coefficients improves average performance on a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Calibration Slope\n",
    "\n",
    "Continuous:\n",
    "- Calibration-in-the-large: Compute $y_{new} - \\hat{y}$, $t$-test null of zero difference; i.e. regress residuals on a constant.\n",
    "- Calibration slope: $y_{new} - \\hat{y} = a + b \\times \\hat{y}$. Seeking $a=0$ and $b=1$.\n",
    "\n",
    "For binary outcomes,\n",
    "$$\n",
    "OR = \\dfrac{m(\\hat{y})}{1- m(\\hat{y})} \\times \\left[ \\dfrac{m(y_{new})}{1-m(y_{new})} \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "$c$ statistic: concordance statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Strong Calibration\n",
    "- Essentially goodness-of-fit\n",
    "- Lack of fit: Missed nonlinearities/interactions, inappropriate link function\n",
    "\n",
    "\n",
    "Another approach to goodness-of-ﬁt is to study observed versus expected out-\n",
    "comes in subgroups of patients, deﬁned by predictor values. For example, we can\n",
    "assess the difference between observed versus expected outcomes in males and\n",
    "females, or other subgroups of patients. If the effect of the subgroup is not well\n",
    "modeled, e.g., an interaction was missed, this might be reﬂected in this assessment.\n",
    "302 15 Evaluation of Performance\n",
    "There are, however, more direct ways of assessing the inﬂuence of subgroup\n",
    "characteristics, as was discussed in Chap. 13 on model speciﬁcation. So, this check\n",
    "for calibration is also more for face validity of the model and for convincing\n",
    "potential users than a serious check of calibration. Measures for assessment of\n",
    "calibration are summarized in Table 15.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kinds of Calibration:\n",
    "\n",
    "| Type              | Definition | Test |\n",
    "| :---------------- | :------: | ----: |\n",
    "| Mean        |  $\\widehat{\\mathbb{E}}[p] = \\dfrac{1}{N} \\sum_{i=1}^N \\hat{p}(x_i)$   | Test $\\hat{a}=0$ assuming that $\\hat{b}=1$ |\n",
    "| Weak           |   No systematic mis-estimation of risks  | Estimate $(a,b)$, test whether $\\hat{a}=0$ and $\\hat{b}=1$ |\n",
    "| Moderate |  $\\widehat{\\mathbb{E}}[p \\| \\hat{p}] = \\hat{p}$,   | Calibration Curve |\n",
    "| Strong |  $\\widehat{\\mathbb{E}}[p(x_i) \\| \\hat{p}(x_i), x_i] = \\hat{p}(x_i)$,   | 42.99 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[602]\n",
    "[26]\n",
    "[225]\n",
    "[109,627]\n",
    "[114] - Calibration slope\n",
    "[257] - Hosmer-Lemeshow GOF test, [225] Harrell's E statistic, Estimated Calibration index (ECI) [621]\n",
    "[602] Utopic model\n",
    "[187, 324]  Goeman-Le Cessie GOF test: An interesting approach is the Goeman–Le Cessie goodness-of-ﬁt test [187,\n",
    "324]. It assesses the alternative hypothesis that any nonlinearities or interaction\n",
    "effects have been missed in a logistic regression model. Such neglected effects can\n",
    "be detected by studying patterns in the residuals: observations close to each other in\n",
    "covariate space which deviate from the model in the same direction.  The approach\n",
    "is to smooth the regression residuals and to test whether these smoothed residuals\n",
    "have more variance than expected under the null hypothesis. This deviation occurs\n",
    "when residuals that are close together in the covariate space are correlated. The test\n",
    "statistic is a sum of squared smoothed residuals.\n",
    "[116] Survival Analysis: A calibration plot can also be produced. The calibration of a model can be\n",
    "studied at ﬁxed time points. We can group patients for calculation of survival rates\n",
    "with the Kaplan–Meier method. Harrell suggests to use at least 50 subjects per\n",
    "group, depending on the hazard of the outcome [225]. This observed survival may\n",
    "be compared to the mean predicted survival from the prediction model. A smoothed\n",
    "calibration curve can be obtained by comparing Cox–Snell residuals on the\n",
    "cumulative probability scale against the right-censored survival times [225]. We can\n",
    "also plot the observed t-year risk of the outcome for each tenth of patients (and 95%\n",
    "conﬁdence intervals) against the predicted risk estimated from the Poisson\n",
    "regression model [116]. This model-based approach can be extended to replace the\n",
    "groups with splines. These approaches depend on the baseline hazard being\n",
    "available either for at least some speciﬁc time points [471].\n",
    "\n",
    "[568] Calibration plot -> Validation plot\n",
    "\n",
    "[629] The calibration slope, however, has\n",
    "a direct mathematical relation with discrimination [629]. If the calibration slope is\n",
    "below unity, the discrimination is also lower at external validation. Hence, over-\n",
    "ﬁtted models will show both poor calibration and poor discrimination when vali-\n",
    "dated in new patients (Chap. 19).\n",
    "\n",
    "[432] Predictiveness curves\n",
    "\n",
    "\n",
    "The framework of a recalibration model was already proposed by Cox [114], and\n",
    "has been supported by many other researchers for evaluation of model performance\n",
    "[109, 225, 379, 380, 626]. Nice illustrations of diagnostic test evaluation with ROC\n",
    "curves are available at: http://www.anaesthetist.com/mnm/stats/roc/ and illustra-\n",
    "tions of Lorenz curves and the Gini index are at: http://en.wikipedia.org/wiki/Gini_\n",
    "coefﬁcient.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Discrimination\n",
    "\n",
    "Nagelkerke’s R2 can well be used [403], although\n",
    "many alternatives are available, and some may prefer other definitions [7].\n",
    "\n",
    "\n",
    "\n",
    "We consider a development sample containing 544 patients [551], and a validation\n",
    "sample 273 patients treated at Indiana University Medical Center [644]. We\n",
    "developed a logistic regression model with five predictors: teratoma elements in the\n",
    "primary tumor, prechemotherapy levels of AFP and HCG, postchemotherapy mass\n",
    "size, and reduction in mass size.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For example, the Brier score can formally be decomposed into\n",
    "indicators of calibration and discrimination [54, 396].\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The area under the curve (AUC) can be interpreted as the probability that a\n",
    "patient with the outcome is given a higher probability of the outcome by the model\n",
    "than a randomly chosen patient without the outcome [223]. An uninformative\n",
    "model, such as a coin flip, will hence have an area of 0.5. A perfect model has an\n",
    "area of 1. The AUC is usually the most important number from a ROC plot; the plot\n",
    "itself suffers from instability and is rather meaningless if no thresholds are indicated\n",
    "(Fig. 15.3, no thresholds, only the area is relevant versus Fig. 15.2, thresholds\n",
    "added).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The Lorenz curve has been used in economics to characterize the\n",
    "distribution of wealth in a population [351]\n",
    "\n",
    "The discrimination slope is a simple measure for how well subjects with and\n",
    "without the outcome are separated. Its use as a measure for discrimination is\n",
    "attributed to Yates [684]. It is easily calculated as the absolute difference in average\n",
    "predictions for those with and without the outcome BOXPLOT CONDITIONAL ON ACTUAL 0,1\n",
    "\n",
    "\n",
    "\n",
    "Indeed, the interesting connection is that Pearson R2 is asymptotically equal to\n",
    "the Yates slope. Improvements in Pearson R2 or in Yates slope are equivalent to the\n",
    "integrated discrimination index (IDI) [426, 428, 568].\n",
    "\n",
    "\n",
    "\n",
    "GINI:\n",
    "For prediction models, we can plot the cumulative proportion of the population\n",
    "on the x-axis, ranked by predicted probability. On the y-axis, we plot the cumu-\n",
    "lative proportion of subjects with the outcome. For example, we can show the\n",
    "proportion of subjects developing cancer against the cumulative proportion of the\n",
    "population ranked by cancer risk [46]. In terms of ROC curves, we plot the\n",
    "cumulative rate of false-negative classifications against the cumulative rate of\n",
    "negative predictions. The ROC and Lorenz curves look somewhat similar, except\n",
    "that the Lorenz curve is flipped vertically and horizontally. In case of a\n",
    "non-informative model, a straight line arises, since every rate of the population\n",
    "classified as negative corresponds to the same rate classified as negative among\n",
    "those with the outcome. A good model has a curve under this straight line, with a\n",
    "relatively large proportion of the population classified as negative having only a\n",
    "small part of the outcomes (low false-negative rate). On the upper end of the x-axis,\n",
    "a small part of the population should contain many subjects with the outcome. In\n",
    "the ideal case, a cutoff is used that classifies the fraction as positive equal to the\n",
    "prevalence, and all these have the outcome. Indeed, we note that a c statistic of 0.98\n",
    "leads to a nearly horizontal line till the 50% cumulative proportion point on the\n",
    "x-axis and increases more or less linearly to 100% after that.\n",
    "The Gini index is sometimes calculated as a summary measure for the Lorenz\n",
    "curve. The Gini index is the ratio between the area A between the Lorenz curve of\n",
    "the prediction model and the line for a non-informative model and the area under\n",
    "the line for a non-informative model (0.5). Hence, G = 2 * A.\n",
    "Other summaries are related to quantiles of the cumulative\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Table 15.5 Summary of some measures for discriminative ability of a prediction model for\n",
    "binary outcomes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOOTSTRAP VALIDATION\n",
    "\n",
    "For bootstrap validation a prediction model is developed in each bootstrap\n",
    "sample. This model is evaluated both in the bootstrap sample and in the original\n",
    "sample. The first reflects apparent validation, the second reflects validation in new\n",
    "subjects. The difference in performance indicates the optimism. This optimism is\n",
    "subtracted from the apparent performance of the original model in the original\n",
    "sample [148, 225, 542, 547]. The bootstrap was illustrated for estimation of opti-\n",
    "mism in Chap. 5.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
